# 大模型Token超限处理技术方案

## 1. 背景介绍

大语言模型(LLM)存在上下文窗口限制，当对话累积的tokens超过模型限制时，需要采取适当策略处理历史消息，确保对话可以持续进行，同时保留关键上下文信息。本文档描述了AgentX系统中实现Token超限处理的技术方案。

## 2. 系统架构概述

Token超限管理是大模型对话系统中的关键组件，帮助系统在长对话中持续运行而不超出模型的上下文限制。系统架构包括：

- **策略管理器**：负责检测和触发Token超限处理
- **策略实现**：包括无策略、滑动窗口和摘要三种策略
- **数据层交互**：与sessions、messages和context表交互

## 3. 处理策略详解

本系统实现了三种Token超限处理策略：

### 3.1 无策略 (No Strategy)

- **原理**：不对消息进行任何处理，直接发送所有消息到LLM
- **适用场景**：短对话或用户自行管理上下文的场景
- **风险**：可能导致Token超限错误，需要用户自行清空对话
- **注意事项**：默认配置选项，适合基础使用

### 3.2 滑动窗口策略 (Sliding Window)

- **原理**：基于Token数量保留最新消息，超出窗口的旧消息将被丢弃
- **优点**：实现简单，无需额外LLM调用，计算开销小
- **缺点**：历史信息会完全丢失，可能影响对话连贯性
- **适用场景**：简单问答、不需要长期记忆的聊天
- **配置参数**：
  - `最大Token数`：窗口大小，必填项，通常设置为所用LLM的上下文限制
  - `预留缓冲比例`：为新消息预留的空间比例，默认为10%

### 3.3 摘要策略 (Summarize)

- **原理**：将超出阈值的早期消息生成摘要，保留摘要和最新消息
- **优点**：保留关键历史信息，同时控制Token使用
- **缺点**：需要额外LLM调用生成摘要，有延迟和成本
- **适用场景**：需要保留长期上下文的深度对话
- **配置参数**：
  - `摘要触发阈值`：触发摘要的消息数量，默认20条
  - `最大Token数`：总Token上限，默认为所用LLM的上下文限制

## 4. 数据流设计

### 4.1 数据表扩展

在现有数据库结构上添加Token管理相关字段：

```
context表：
- overflow_strategy：策略类型（无策略/滑动窗口/摘要）
- strategy_config：策略配置参数（JSON格式）
- summary：对话摘要内容

agents表和agent_versions表：
- token_overflow_config：Token超限配置（JSON格式）
```

### 4.2 核心数据流

当用户发送消息时，系统处理流程如下：

1. 用户发送新消息 → 消息保存到messages表
2. 系统检查当前策略和token使用情况
3. 如触发超限条件，执行相应策略：
   - 无策略：不做任何处理
   - 滑动窗口：移除旧消息直到满足token限制
   - 摘要：将早期消息摘要化，保留新消息
4. 更新context表中的active_messages和summary
5. 构建发送给LLM的消息列表
6. 接收LLM回复并返回给用户

## 5. 摘要策略详细流程

### 5.1 摘要生成流程

1. **触发条件检测**：
   - 当active_messages数量超过设定阈值（如20条）
   - 或当总token数接近上限（如达到最大值的80%）

2. **消息分组**：
   - 提取最早的N条消息用于摘要生成
   - 保留最新的消息（通常为阈值数量）

3. **摘要生成**：
   - 首次摘要：直接对早期消息生成摘要
   - 后续摘要：将新摘要内容与已有摘要整合

4. **上下文更新**：
   - 更新context.summary字段存储摘要
   - 更新context.active_messages仅保留较新消息ID

### 5.2 摘要与LLM交互

发送给LLM的消息结构：
1. 系统指令（如agent系统提示）
2. 摘要内容（作为system消息提供历史上下文）
3. 保留的active_messages消息内容

### 5.3 实例场景

假设一个具有25条消息的对话，配置为超过20条触发摘要：

1. **初始状态**：
   - context.active_messages包含25条message_id
   
2. **触发摘要**：
   - 提取最早的5条消息生成摘要
   - context.summary保存这5条消息的摘要
   - context.active_messages更新为只包含最新20条消息ID

3. **后续对话**：
   - 用户又发送5条新消息，active_messages增加到25条
   - 再次触发摘要处理
   - 取出最早的5条消息，与已有摘要合并生成新摘要
   - context.summary更新为合并后的摘要
   - context.active_messages更新为只包含最新20条

## 6. 滑动窗口策略详细流程

### 6.1 基于Token的滑动窗口处理

1. **Token计算**：
   - 计算每条消息的token数量
   - 计算当前context中的总token使用量

2. **消息筛选**：
   - 从最新消息开始，按时间倒序添加消息
   - 直到累计token接近但不超过设定上限
   - 预留一定比例空间（如10%）给未来消息

3. **上下文更新**：
   - 更新context.active_messages仅保留筛选后的消息ID
   - 舍弃未保留的早期消息（不生成摘要）

### 6.2 实例场景

假设用户配置了8000 token的滑动窗口，当前有多条消息：

1. **初始状态**：
   - 所有消息总token数为9500，超出限制
   
2. **触发处理**：
   - 系统计算每条消息的token数
   - 从最新消息开始，保留消息直到累计约7200 token（预留10%空间）
   - 更早的消息被丢弃
   - context.active_messages更新为保留的消息ID

3. **后续对话**：
   - 用户继续发送消息，总token再次接近限制
   - 系统再次执行滑动窗口，移除最旧的部分消息

## 7. 前端交互设计

### 7.1 配置界面设计

Agent编辑页面中添加"Token管理"区域，包含以下内容：

1. **策略选择部分**：
   - 单选框列表，包含三个选项：
     - 无策略（默认选项）
     - 滑动窗口
     - 摘要策略

2. **参数配置部分**（根据所选策略动态显示）：
   - 滑动窗口策略选中时：
     - 最大Token数（必填）：提供输入框，默认为模型最大值
     - 常见模型预设选项：提供GPT-3.5(4K)、GPT-4(8K)等快速选择
   
   - 摘要策略选中时：
     - 摘要触发阈值：消息数量输入框，默认值20
     - 最大Token数：提供输入框，默认为模型最大值

3. **保存按钮**：
   - 保存配置到agent的token_overflow_config字段

### 7.2 用户交互流程

1. 用户创建/编辑Agent时配置Token策略：
   - 从三种策略中选择一种
   - 填写相应参数（如滑动窗口大小或摘要触发阈值）
   - 保存配置

2. 对话过程中Token管理自动运行：
   - 系统根据配置自动处理Token超限情况
   - 用户无需额外操作，体验无缝衔接

3. 策略切换处理：
   - 当更改Agent的策略后，仅对新创建的会话生效
   - 已有会话继续使用创建时的策略
   - 可选提供"更新已有会话策略"功能（管理员使用）

### 7.3 界面示例

**Agent编辑页Token管理区域**:

```
[ Token管理设置 ]

策略选择:
○ 无策略 - 不做任何处理，可能导致超限错误
● 滑动窗口 - 自动移除旧消息，保留最新内容
○ 摘要 - 将旧消息转换为摘要，保留关键信息

滑动窗口配置:
最大Token数: [8000] (必填)
常用预设: [GPT-4 (8K)] ▼

[  保存配置  ]
```

**摘要策略选中时**:

```
[ Token管理设置 ]

策略选择:
○ 无策略 - 不做任何处理，可能导致超限错误
○ 滑动窗口 - 自动移除旧消息，保留最新内容
● 摘要 - 将旧消息转换为摘要，保留关键信息

摘要策略配置:
摘要触发阈值: [20] 条消息
最大Token数: [8000]

[  保存配置  ]
```

## 8. 实现重点与建议

### 8.1 性能优化

- 对高频Token计算结果进行缓存
- 对摘要生成的调用使用异步处理
- 考虑批处理机制减少数据库访问

### 8.2 用户体验优化

- 在Agent配置时提供Token策略的说明和建议
- 为不同类型Agent提供默认推荐策略
- 考虑在界面上显示当前使用的策略和摘要状态

### 8.3 扩展性考虑

- 设计策略接口支持未来添加新策略
- 考虑混合策略的可能性（如摘要+滑动窗口结合）
- 支持策略参数的动态调整

## 9. 部署与运维注意事项

- 添加Token使用和策略触发的监控指标
- 为摘要生成提供错误处理和重试机制
- 建立摘要质量评估机制，确保信息不丢失

## 10. 未来优化方向

1. 自适应策略：根据对话特点自动调整策略参数
2. 用户反馈整合：允许用户对摘要内容提供反馈
3. 多级摘要：支持摘要的摘要，处理超长对话
4. 可视化工具：提供Token使用和摘要状态的可视化界面 